{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supress Warnings\n",
    "import warnings\n",
    "import pickle\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Visualization\n",
    "import ipyleaflet\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image\n",
    "import seaborn as sns\n",
    "\n",
    "# Data Science\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Feature Engineering\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Machine Learning\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, ConvLSTM2D, BatchNormalization\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "# Planetary Computer Tools\n",
    "import pystac_client\n",
    "from pystac_client import Client\n",
    "from pystac.extensions.eo import EOExtension as eo\n",
    "from odc.stac import stac_load\n",
    "import planetary_computer as pc\n",
    "pc.settings.set_subscription_key('58d635c0d3194d65b98b857cf6966e7f')\n",
    "\n",
    "# Others\n",
    "from itertools import cycle\n",
    "from tqdm import tqdm   \n",
    "import joblib\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process datasets to be uniform in the number of timsteps and pixels per sample \n",
    "def reshapeData3D(dataset, pixel, instances):\n",
    "    dataset_reshaped1 = []\n",
    "    for i in dataset:\n",
    "        if i.shape[2] > pixel and i.shape[1] > pixel:\n",
    "            dataset_reshaped1.append(i[:,:(pixel-i.shape[1]),:(pixel-i.shape[2])])\n",
    "        elif i.shape[1] > pixel:\n",
    "            dataset_reshaped1.append(i[:,:(pixel-i.shape[1]),:])\n",
    "        elif i.shape[2] > pixel:\n",
    "            dataset_reshaped1.append(i[:,:,:(pixel-i.shape[2])])\n",
    "        else:\n",
    "            dataset_reshaped1.append(i)\n",
    "\n",
    "    dataset_reshaped = []\n",
    "    for i in dataset_reshaped1:\n",
    "        if i.shape[0] >instances:\n",
    "            dataset_reshaped.append(i[:instances,:,:])\n",
    "        else:\n",
    "            dataset_reshaped.append((i[:,:,:]))\n",
    "    return [np.transpose(i) for i in dataset_reshaped]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opens pickled data from scraped files\n",
    "def read_file(month):\n",
    "    with open(f'{month}.pkl', 'rb') as file:\n",
    "        return pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracts data for each sample from time_of_interest, coordinates, and boxsize/resolution\n",
    "def getData(time_of_interest, lat_long, box_size_deg, resolution):\n",
    "    latlong=lat_long.replace('(','').replace(')','').replace(' ','').split(',')\n",
    "    bbox = (float(latlong[1])-box_size_deg/2, float(latlong[0])-box_size_deg/2, float(latlong[1])+box_size_deg/2, float(latlong[0])+box_size_deg/2)\n",
    "    catalog = pystac_client.Client.open(\"https://planetarycomputer.microsoft.com/api/stac/v1\", modifier=pc.sign_inplace)\n",
    "    search = catalog.search(collections=[\"sentinel-1-rtc\"], bbox=bbox, datetime=time_of_interest)\n",
    "    items = list(search.get_all_items())\n",
    "    scale = resolution / 111320.0 \n",
    "    data = stac_load(items,bands=[\"vv\", 'vh'], patch_url=pc.sign, bbox=bbox, crs=\"EPSG:4326\", resolution=scale)\n",
    "    VV = np.array(data.vv)\n",
    "    VH = np.array(data.vh)\n",
    "    return VV, VH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Scraping (Deployed on Microsoft Planetary Computer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m VV, VH \u001b[39m=\u001b[39m [], []\n\u001b[1;32m     15\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m coordinates:\n\u001b[0;32m---> 16\u001b[0m     vv, vh \u001b[39m=\u001b[39m getData(time_of_interest, i, box_size_deg, resolution)\n\u001b[1;32m     17\u001b[0m     VV\u001b[39m.\u001b[39mappend(vv)\n\u001b[1;32m     18\u001b[0m     VH\u001b[39m.\u001b[39mappend(vh)\n",
      "Cell \u001b[0;32mIn[26], line 9\u001b[0m, in \u001b[0;36mgetData\u001b[0;34m(time_of_interest, lat_long, box_size_deg, resolution)\u001b[0m\n\u001b[1;32m      7\u001b[0m items \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(search\u001b[39m.\u001b[39mget_all_items())\n\u001b[1;32m      8\u001b[0m scale \u001b[39m=\u001b[39m resolution \u001b[39m/\u001b[39m \u001b[39m111320.0\u001b[39m \n\u001b[0;32m----> 9\u001b[0m data \u001b[39m=\u001b[39m stac_load(items,bands\u001b[39m=\u001b[39;49m[\u001b[39m\"\u001b[39;49m\u001b[39mvv\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mvh\u001b[39;49m\u001b[39m'\u001b[39;49m], patch_url\u001b[39m=\u001b[39;49mpc\u001b[39m.\u001b[39;49msign, bbox\u001b[39m=\u001b[39;49mbbox, crs\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mEPSG:4326\u001b[39;49m\u001b[39m\"\u001b[39;49m, resolution\u001b[39m=\u001b[39;49mscale)\n\u001b[1;32m     10\u001b[0m VV \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(data\u001b[39m.\u001b[39mvv)\n\u001b[1;32m     11\u001b[0m VH \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(data\u001b[39m.\u001b[39mvh)\n",
      "File \u001b[0;32m~/miniforge3/envs/RugaruCheque/lib/python3.10/site-packages/odc/stac/_load.py:610\u001b[0m, in \u001b[0;36mload\u001b[0;34m(items, bands, groupby, resampling, dtype, chunks, pool, crs, resolution, anchor, geobox, bbox, lon, lat, x, y, like, geopolygon, progress, fail_on_error, stac_cfg, patch_url, preserve_original_order, **kw)\u001b[0m\n\u001b[1;32m    607\u001b[0m \u001b[39mif\u001b[39;00m progress \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    608\u001b[0m     _work \u001b[39m=\u001b[39m progress(SizedIterable(_work, total_tasks))\n\u001b[0;32m--> 610\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m _work:\n\u001b[1;32m    611\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[1;32m    613\u001b[0m \u001b[39mreturn\u001b[39;00m _with_debug_info(ds, tasks\u001b[39m=\u001b[39m_tasks)\n",
      "File \u001b[0;32m~/miniforge3/envs/RugaruCheque/lib/python3.10/site-packages/odc/stac/_utils.py:38\u001b[0m, in \u001b[0;36mpmap\u001b[0;34m(func, inputs, pool)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[39mWrapper for ThreadPoolExecutor.map\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[39mif\u001b[39;00m pool \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m---> 38\u001b[0m     \u001b[39myield from\u001b[39;00m \u001b[39mmap\u001b[39m(func, inputs)\n\u001b[1;32m     39\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(pool, \u001b[39mint\u001b[39m):\n",
      "File \u001b[0;32m~/miniforge3/envs/RugaruCheque/lib/python3.10/site-packages/odc/stac/_load.py:601\u001b[0m, in \u001b[0;36mload.<locals>._do_one\u001b[0;34m(task)\u001b[0m\n\u001b[1;32m    595\u001b[0m srcs \u001b[39m=\u001b[39m [\n\u001b[1;32m    596\u001b[0m     src\n\u001b[1;32m    597\u001b[0m     \u001b[39mfor\u001b[39;00m src \u001b[39min\u001b[39;00m (_parsed[idx]\u001b[39m.\u001b[39mget(band, \u001b[39mNone\u001b[39;00m) \u001b[39mfor\u001b[39;00m idx, band \u001b[39min\u001b[39;00m task\u001b[39m.\u001b[39msrcs)\n\u001b[1;32m    598\u001b[0m     \u001b[39mif\u001b[39;00m src \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    599\u001b[0m ]\n\u001b[1;32m    600\u001b[0m \u001b[39mwith\u001b[39;00m rio_env(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m_rio_env):\n\u001b[0;32m--> 601\u001b[0m     _ \u001b[39m=\u001b[39m _fill_2d_slice(srcs, task\u001b[39m.\u001b[39;49mdst_gbox, task\u001b[39m.\u001b[39;49mcfg, dst_slice)\n\u001b[1;32m    602\u001b[0m t, y, x \u001b[39m=\u001b[39m task\u001b[39m.\u001b[39midx_tyx\n\u001b[1;32m    603\u001b[0m \u001b[39mreturn\u001b[39;00m (task\u001b[39m.\u001b[39mband, t, y, x)\n",
      "File \u001b[0;32m~/miniforge3/envs/RugaruCheque/lib/python3.10/site-packages/odc/stac/_load.py:698\u001b[0m, in \u001b[0;36m_fill_2d_slice\u001b[0;34m(srcs, dst_gbox, cfg, dst)\u001b[0m\n\u001b[1;32m    695\u001b[0m     \u001b[39mreturn\u001b[39;00m dst\n\u001b[1;32m    697\u001b[0m src, \u001b[39m*\u001b[39mrest \u001b[39m=\u001b[39m srcs\n\u001b[0;32m--> 698\u001b[0m _roi, pix \u001b[39m=\u001b[39m rio_read(src, cfg, dst_gbox, dst\u001b[39m=\u001b[39;49mdst)\n\u001b[1;32m    700\u001b[0m \u001b[39mfor\u001b[39;00m src \u001b[39min\u001b[39;00m rest:\n\u001b[1;32m    701\u001b[0m     \u001b[39m# first valid pixel takes precedence over others\u001b[39;00m\n\u001b[1;32m    702\u001b[0m     _roi, pix \u001b[39m=\u001b[39m rio_read(src, cfg, dst_gbox)\n",
      "File \u001b[0;32m~/miniforge3/envs/RugaruCheque/lib/python3.10/site-packages/odc/stac/_reader.py:186\u001b[0m, in \u001b[0;36mrio_read\u001b[0;34m(src, cfg, dst_geobox, dst)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    164\u001b[0m \u001b[39mInternal read method.\u001b[39;00m\n\u001b[1;32m    165\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    182\u001b[0m \n\u001b[1;32m    183\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    185\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 186\u001b[0m     \u001b[39mreturn\u001b[39;00m _rio_read(src, cfg, dst_geobox, dst)\n\u001b[1;32m    187\u001b[0m \u001b[39mexcept\u001b[39;00m rasterio\u001b[39m.\u001b[39merrors\u001b[39m.\u001b[39mRasterioIOError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    188\u001b[0m     \u001b[39mif\u001b[39;00m cfg\u001b[39m.\u001b[39mfail_on_error:\n",
      "File \u001b[0;32m~/miniforge3/envs/RugaruCheque/lib/python3.10/site-packages/odc/stac/_reader.py:219\u001b[0m, in \u001b[0;36m_rio_read\u001b[0;34m(src, cfg, dst_geobox, dst)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_rio_read\u001b[39m(\n\u001b[1;32m    210\u001b[0m     src: RasterSource,\n\u001b[1;32m    211\u001b[0m     cfg: RasterLoadParams,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[39m# if resampling is `nearest` then ignore sub-pixel translation when deciding\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[39m# whether we can just paste source into destination\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     ttol \u001b[39m=\u001b[39m \u001b[39m0.9\u001b[39m \u001b[39mif\u001b[39;00m cfg\u001b[39m.\u001b[39mnearest \u001b[39melse\u001b[39;00m \u001b[39m0.05\u001b[39m\n\u001b[0;32m--> 219\u001b[0m     \u001b[39mwith\u001b[39;00m rasterio\u001b[39m.\u001b[39;49mopen(src\u001b[39m.\u001b[39;49muri, \u001b[39m\"\u001b[39;49m\u001b[39mr\u001b[39;49m\u001b[39m\"\u001b[39;49m, sharing\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m) \u001b[39mas\u001b[39;00m rdr:\n\u001b[1;32m    220\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(rdr, rasterio\u001b[39m.\u001b[39mDatasetReader)\n\u001b[1;32m    221\u001b[0m         ovr_idx: Optional[\u001b[39mint\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/RugaruCheque/lib/python3.10/site-packages/rasterio/env.py:451\u001b[0m, in \u001b[0;36mensure_env_with_credentials.<locals>.wrapper\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    448\u001b[0m     session \u001b[39m=\u001b[39m DummySession()\n\u001b[1;32m    450\u001b[0m \u001b[39mwith\u001b[39;00m env_ctor(session\u001b[39m=\u001b[39msession):\n\u001b[0;32m--> 451\u001b[0m     \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n",
      "File \u001b[0;32m~/miniforge3/envs/RugaruCheque/lib/python3.10/site-packages/rasterio/__init__.py:304\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(fp, mode, driver, width, height, count, crs, transform, dtype, nodata, sharing, **kwargs)\u001b[0m\n\u001b[1;32m    301\u001b[0m path \u001b[39m=\u001b[39m _parse_path(raw_dataset_path)\n\u001b[1;32m    303\u001b[0m \u001b[39mif\u001b[39;00m mode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 304\u001b[0m     dataset \u001b[39m=\u001b[39m DatasetReader(path, driver\u001b[39m=\u001b[39;49mdriver, sharing\u001b[39m=\u001b[39;49msharing, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    305\u001b[0m \u001b[39melif\u001b[39;00m mode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mr+\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    306\u001b[0m     dataset \u001b[39m=\u001b[39m get_writer_for_path(path, driver\u001b[39m=\u001b[39mdriver)(\n\u001b[1;32m    307\u001b[0m         path, mode, driver\u001b[39m=\u001b[39mdriver, sharing\u001b[39m=\u001b[39msharing, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[1;32m    308\u001b[0m     )\n",
      "File \u001b[0;32mrasterio/_base.pyx:312\u001b[0m, in \u001b[0;36mrasterio._base.DatasetBase.__init__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniforge3/envs/RugaruCheque/lib/python3.10/site-packages/rasterio/_path.py:81\u001b[0m, in \u001b[0;36m_ParsedPath.name\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     78\u001b[0m     archive \u001b[39m=\u001b[39m parts\u001b[39m.\u001b[39mpop() \u001b[39mif\u001b[39;00m parts \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     79\u001b[0m     \u001b[39mreturn\u001b[39;00m _ParsedPath(path, archive, scheme)\n\u001b[0;32m---> 81\u001b[0m \u001b[39m@property\u001b[39m\n\u001b[1;32m     82\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mname\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m     83\u001b[0m     \u001b[39m\"\"\"The parsed path's original URI\"\"\"\u001b[39;00m\n\u001b[1;32m     84\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscheme:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Extract coordinate samples from training and test sets\n",
    "df = list(pd.read_csv('Crop_Location_Data.csv')['Latitude and Longitude'])\n",
    "df2 = list(pd.read_csv('challenge_1_submission_template.csv')['id'])\n",
    "\n",
    "#Set coordinates for data scraping\n",
    "coordinates = df + df2\n",
    "# Yields 24 timesteps of the same sample\n",
    "time_of_interest = \"2022-04-01/2022-08-31\" \n",
    "#Yields a closeup, 90x90 pixel image per sample\n",
    "box_size_deg = 0.008 \n",
    "resolution = 10 \n",
    "\n",
    "#Scraping data from planetary computer\n",
    "VV, VH = [], []\n",
    "for i in coordinates:\n",
    "    vv, vh = getData(time_of_interest, i, box_size_deg, resolution)\n",
    "    VV.append(vv)\n",
    "    VH.append(vh)\n",
    "    print(len(VH))\n",
    "\n",
    "#Saving data from planetary computer into pickle files as lists\n",
    "with open(\"APR-AUG_VV.pkl\", 'wb') as save:\n",
    "    pickle.dump(VV, save)\n",
    "with open(\"APR-AUG_VH.pkl\", 'wb') as save:\n",
    "    pickle.dump(VH, save)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standardising the shape of VV and VH data samples\n",
    "VH = reshapeData3D(read_file('APR-AUG_VH'), 90, 24)\n",
    "VV = reshapeData3D(read_file('APR-AUG_VV'), 90, 24)\n",
    "\n",
    "#Performing matrix calculations to derive the RGB values for each sample\n",
    "RGB = []\n",
    "for i in range(len(VV)):\n",
    "    RGB.append(np.reshape(np.stack([VH[i], VV[i], np.divide(VH[i], VV[i])]), (1,24, 90, 90, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(850, 24, 3, 90, 90)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reshaping training data to represent the tuple: (number of samples, timesteps, dimensions, pixels X, pixels Y)\n",
    "X = np.array(RGB).reshape(850, 24, 3, 90, 90)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encoding Labels\n",
    "oe = LabelEncoder()\n",
    "y = oe.fit_transform(pd.read_csv('Crop_Location_Data.csv')['Class of Land'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting Data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X[:600], y[:600], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Fitting and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a tensorflow sequential network\n",
    "model = Sequential()\n",
    "\n",
    "#1st layer of Convolutional LSTM \n",
    "model.add(ConvLSTM2D(filters=16, kernel_size=(3, 3), input_shape=(X_train.shape[1], X_train.shape[2], X_train.shape[3], X_train.shape[4]), padding='same', return_sequences=True))\n",
    "model.add(BatchNormalization(axis=(2,3)))\n",
    "\n",
    "#2nd layer of Convolutional LSTM \n",
    "model.add(ConvLSTM2D(filters=32, kernel_size=(3, 3), padding='same', return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization(axis=(2,3)))\n",
    "\n",
    "#3rd layer of Convolutional LSTM \n",
    "model.add(ConvLSTM2D(filters=64, kernel_size=(3, 3), padding='same', return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization(axis=(2,3)))\n",
    "\n",
    "#Additional Bath Normalisation \n",
    "model.add(BatchNormalization(axis=(2,3)))\n",
    "\n",
    "#Flatten network results \n",
    "model.add(Flatten())\n",
    "\n",
    "#Feed flattened data through a dense sigmoid neuron to produce a binary inference\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "#Compile model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.001), loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-11 17:58:45.656092: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - ETA: 0s - loss: 12.9351 - accuracy: 0.6979"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-11 18:02:52.934547: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 259s 3s/step - loss: 12.9351 - accuracy: 0.6979 - val_loss: 10.9191 - val_accuracy: 0.5167\n",
      "Epoch 2/10\n",
      "96/96 [==============================] - 243s 3s/step - loss: 6.6668 - accuracy: 0.8292 - val_loss: 1.3906 - val_accuracy: 0.9417\n",
      "Epoch 3/10\n",
      "96/96 [==============================] - 228s 2s/step - loss: 6.7751 - accuracy: 0.8792 - val_loss: 0.9881 - val_accuracy: 0.9917\n",
      "Epoch 4/10\n",
      "96/96 [==============================] - 228s 2s/step - loss: 2.1295 - accuracy: 0.9625 - val_loss: 3.3249 - val_accuracy: 0.9667\n",
      "Epoch 5/10\n",
      "96/96 [==============================] - 231s 2s/step - loss: 1.9519 - accuracy: 0.9688 - val_loss: 0.6651 - val_accuracy: 0.9583\n",
      "Epoch 6/10\n",
      "96/96 [==============================] - 234s 2s/step - loss: 4.4133 - accuracy: 0.9521 - val_loss: 2.4687 - val_accuracy: 0.9667\n",
      "Epoch 7/10\n",
      "96/96 [==============================] - 236s 2s/step - loss: 3.1074 - accuracy: 0.9563 - val_loss: 5.4202 - val_accuracy: 0.9250\n",
      "Epoch 8/10\n",
      "96/96 [==============================] - 243s 3s/step - loss: 2.2404 - accuracy: 0.9667 - val_loss: 1.8213e-06 - val_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "96/96 [==============================] - 225s 2s/step - loss: 3.3913 - accuracy: 0.9688 - val_loss: 1.1501 - val_accuracy: 0.9917\n",
      "Epoch 10/10\n",
      "96/96 [==============================] - 226s 2s/step - loss: 0.0260 - accuracy: 0.9938 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "INFO:tensorflow:Assets written to: ConvLSTM_1.0/assets\n"
     ]
    }
   ],
   "source": [
    "#Early stopping in the case of overfitting\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=5)\n",
    "\n",
    "#Fit the model to training and validation sets\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=5, validation_data=(X_val, y_val), callbacks=[early_stopping])\n",
    "\n",
    "#Save the model as a pickle file\n",
    "model.save('ConvLSTM_1.0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results Rendering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-12 01:14:38.401332: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-03-12 01:14:38.401962: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Pro\n",
      "\n",
      "systemMemory: 32.00 GB\n",
      "maxCacheSize: 10.67 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-12 01:14:44.994963: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2023-03-12 01:14:45.322361: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 6s 468ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(10.18019073690894, 105.32022315786804)</td>\n",
       "      <td>Rice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(10.561107033461816, 105.12772097986661)</td>\n",
       "      <td>Rice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(10.623790611954897, 105.13771401411867)</td>\n",
       "      <td>Rice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(10.583364246115156, 105.23946127195805)</td>\n",
       "      <td>Non Rice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(10.20744446668854, 105.26844107128906)</td>\n",
       "      <td>Rice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>(10.308283266873062, 105.50872812216863)</td>\n",
       "      <td>Non Rice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>(10.582910017285496, 105.23991550078767)</td>\n",
       "      <td>Non Rice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>(10.581547330796518, 105.23991550078767)</td>\n",
       "      <td>Non Rice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>(10.629241357910818, 105.15315779432643)</td>\n",
       "      <td>Rice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>(10.574733898351617, 105.10410108072531)</td>\n",
       "      <td>Rice</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           id    target\n",
       "0     (10.18019073690894, 105.32022315786804)      Rice\n",
       "1    (10.561107033461816, 105.12772097986661)      Rice\n",
       "2    (10.623790611954897, 105.13771401411867)      Rice\n",
       "3    (10.583364246115156, 105.23946127195805)  Non Rice\n",
       "4     (10.20744446668854, 105.26844107128906)      Rice\n",
       "..                                        ...       ...\n",
       "245  (10.308283266873062, 105.50872812216863)  Non Rice\n",
       "246  (10.582910017285496, 105.23991550078767)  Non Rice\n",
       "247  (10.581547330796518, 105.23991550078767)  Non Rice\n",
       "248  (10.629241357910818, 105.15315779432643)      Rice\n",
       "249  (10.574733898351617, 105.10410108072531)      Rice\n",
       "\n",
       "[250 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load the model to predict test samples\n",
    "model =  keras.models.load_model('ConvLSTM_1.0')\n",
    "y_pred = model.predict(X[600:])\n",
    "\n",
    "#Convert the binary inference of the model into discrete labels; if 1 = Rice, if 0 = Not Rice)\n",
    "result = []\n",
    "for i in y_pred:\n",
    "    if i>0.5:\n",
    "        result.append('Rice')\n",
    "    else:\n",
    "        result.append('Non Rice')\n",
    "\n",
    "#Load the test sample training dataimage.png\n",
    "submission = pd.read_csv('challenge_1_submission_template.csv')\n",
    "submission['target'] = result\n",
    "submission.to_csv(\"1.0tests.csv\")\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "b763176424bcb8a9d9f114c34ce746603bfc5bac3b39daa49836d2e7ffb8d010"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
